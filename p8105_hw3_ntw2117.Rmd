---
title: "P8105: Homework 3"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

theme_set(theme_bw(base_size = 8))
```

## Problem 1

#### Importing and cleaning BRFSS data 

```{r importing brfss data}
brfss_data <- p8105.datasets::brfss_smart2010 %>% 
  janitor::clean_names()

brfss_data <- brfss_data %>% 
  rename(state = locationabbr, 
         location = locationdesc) %>% 
  filter(topic == "Overall Health") %>% 
  select(-(class:question), 
                       -sample_size, 
                       -(confidence_limit_low:geo_location)) %>% 
  mutate(response = as.factor(response))

brfss_data$response <- fct_relevel(brfss_data$response, 
                                   "Excellent", 
                                   "Very good", 
                                   "Good")
```

#### Questions and plots

```{r calculating 7 obs in 2002}
brfss_data %>% 
  filter(year == 2002) %>% 
  distinct(state, location) %>% 
  count(state) %>% 
  filter(n == 7) %>% 
  knitr::kable()
```

In 2002, the states Connecticut, Florida, and North Carolina were observed at 7 locations. 

```{r creating spaghetti plot, out.width = "90%", fig.align = "center", dpi = 300}
brfss_data %>% 
  group_by(state, year) %>% 
  distinct(location) %>% 
  count(state) %>% 
  ggplot(aes(x = year, y = n)) + 
    geom_line(aes(color = state)) + 
    viridis::scale_color_viridis(
      name = "", 
      discrete = TRUE, 
      option = "magma") +
    labs(title = "Figure 1: Spaghetti plot of number of locations across states from 2002 to 2010", 
         x = "Year", 
         y = "Number of Locations") + 
    theme(legend.position = "bottom", 
          legend.direction = "horizontal", 
          legend.key.width = unit(.125, "in")) + 
    guides(color = guide_legend(ncol = 17))
```

Figure 1 shows the trends in the number of locations across all 50 states and the District of Columbia. From 2002 to 2010, all states except Florida had less than 20 locations. Furthermore, it appears that most states had a relatively constant number of locations over the eight year period. 

```{r table proportion excellent responses NY 2002/06/10, fig.align = "center"}
brfss_data %>% 
  filter(year %in% c(2002, 2006, 2010), 
         state == "NY") %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(prop_excel =  (excellent) / (excellent + fair + good + poor + very_good)) %>% 
  group_by(year) %>% 
  summarize("Average proportion excellent" = round(mean(prop_excel), 4), 
            "Standard deviation" = round(sd(prop_excel), 4)) %>% 
  rename(Year = year) %>% 
  knitr::kable()
```

Table 2 contains the average proportion of excellent responses across locations in New York for 2002, 2006, and 2010. A small decrease is observed from 2002 to 2006 and then remains constant from 2006 to 2010. The standard error decreases in 2010, most likely indicating that more responses were collected that year. 

```{r average proportion response category across location by state, warning = FALSE, fig.height = 8, fig.align = "center", dpi = 300}
library(patchwork)

avg_response_year_state <- 
  brfss_data %>%
  mutate(year = as.factor(year)) %>% 
  group_by(year, state, response) %>%
  summarize(avg_response = mean(data_value))

poor_dist <- avg_response_year_state %>%
  filter(response == "Poor") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) + 
    geom_text(x = 0, y = 0.40, 
              label = "Poor", 
              size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    viridis::scale_fill_viridis(discrete = TRUE, 
                                option = "magma",
                                guide = FALSE) + 
    theme(axis.text.x = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) + 
    labs(title = "Figure 2: Density plots of the proportion of different respones across states from 2002 to 2010", 
         y = "", 
         x = "")

fair_dist <- avg_response_year_state %>%
  filter(response == "Fair") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) +
    geom_text(x = 0, y = 0.15, 
              label = "Fair", size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    viridis::scale_fill_viridis(discrete = TRUE, 
                                option = "magma",
                                guide = FALSE) + 
    theme(axis.text.x = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) + 
    labs(y = "", x = "")

good_dist <- avg_response_year_state %>%
  filter(response == "Good") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) +
    geom_text(x = 0, y = 0.15, 
              label = "Good", size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    viridis::scale_fill_viridis(discrete = TRUE, 
                                option = "magma", 
                                guide = FALSE) + 
    theme(axis.text.x = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) +
    labs(y = "", x = "") 

v_good_dist <- avg_response_year_state %>%
  filter(response == "Very good") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) +
    geom_text(x = 1, y = 0.125, 
              label = "Very good", size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    viridis::scale_fill_viridis(discrete = TRUE, 
                                option = "magma",
                                guide = FALSE) + 
    theme(axis.text.x = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) + 
    labs(y = "", x = "")

excel_dist <- avg_response_year_state %>%
  filter(response == "Excellent") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) +
    geom_text(x = 1, y = 0.15, 
              label = "Excellent", size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    labs(y = "", x = "Response proportion") +
    viridis::scale_fill_viridis(name = "Year",
                                discrete = TRUE, 
                                option = "magma") + 
    theme(legend.position = "bottom",
          legend.direction = "horizontal", 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) + 
    guides(fill = guide_legend(ncol = 10)) 
    

poor_dist / fair_dist / good_dist / v_good_dist / excel_dist
```

Figure 2 shows density plots of the different response categories from 2002 to 2010. Because all of the plots are on the same scale, you can observe the average increase in the proportion of responses from poor up to very good. After very good, the proportion of responses then slightly decreases for the excellent category. It also appears that the distributions within each category remains relatively constant, likely indicating that response does not vary over time. 

## Problem 2

```{r importing insta cart data}
insta_data <- p8105.datasets::instacart %>% 
  janitor::clean_names() %>% 
  mutate(order_dow = order_dow + 1)

days <- c("Sunday",
          "Monday",
          "Tuesday",
          "Wednesday",
          "Thursday",
          "Friday",
          "Saturday")

insta_data$order_dow <- days[insta_data$order_dow]


insta_data$order_dow <- fct_relevel(insta_data$order_dow,
                                    "Sunday",
                                    "Monday",
                                    "Tuesday",
                                    "Wednesday",
                                    "Thursday",
                                    "Friday",
                                    "Saturday")
```

```{r aisles information}
numb_orders <- insta_data %>%
  group_by(aisle) %>%
  summarize(n = n()) %>%
  arrange(desc(n))
```

There are `r insta_data %>% distinct(aisle_id) %>% count()` aisles in the dataset. 

```{r items ordered in each aisle, fig.height = 15, fig.align = "center", dpi = 300}
numb_orders %>% 
  mutate(aisle = forcats::fct_reorder(aisle, n, .desc = TRUE)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  coord_flip() + 
  geom_bar(stat = "identity", fill = "#a888bd") +
    labs(y = "Number of Orders", 
        x = "Aisle") + 
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) 
```

```{r most popular items in 3 aisles}
insta_data %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(n = n()) %>% 
  filter(n == max(n)) %>% 
  knitr::kable()
```

```{r mean hour of the day}
insta_data %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(avg_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = avg_hour) %>% 
  rename("Product Name" = product_name) %>% 
  knitr::kable(align = "c")
```

## Problem 3

```{r importing and cleaning NY NOAA data}
noaa_data <- p8105.datasets::ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(date, c("year", "month", "day"), sep = "-") %>% 
  mutate(tmax = as.double(tmax) / 10, 
         tmin = as.double(tmin) / 10, 
         prcp = prcp / 10,
         month = month.name[as.integer(month)], 
         year = as.integer(year))
```

```{r average snow}
noaa_data %>% 
  group_by(month) %>% 
  summarize(avg_snow = round(mean(snow, na.rm = TRUE), 4))
```

```{r average daily temp plot in january and july, dpi = 300,fig.align = "center", fig.retina = 1, fig.asp = .6}
avg_daily_temp <- noaa_data %>%
  filter(month %in% c("January", "July")) %>%
  mutate(avg_temp = (tmin + tmax) / 2)

avg_daily_temp %>% 
  filter(month %in% c("January", "July")) %>% 
  group_by(year, month) %>% 
  summarize(avg_temp = mean(avg_temp, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = avg_temp)) + 
    geom_line(color = "#7496D2", size = 1) + 
  facet_grid(~ month, 
             scales = "free") + 
  labs(x = "Year", 
       y = "Average Daily Temperature (°C)") +
  theme(axis.text.x = element_text(angle = 45,
                                   vjust = 0.4), 
        strip.background = element_rect(fill = "black"), 
        strip.text = element_text(color = "white", 
                                  face = "bold"))
```

```{r snow and temperature plot, dpi = 300, out.width = "100%", fig.asp = .5, fig.align = "center", fig.height = 6}
temp_hex <- noaa_data %>%
  filter(!is.na(tmin),
         !is.na(tmax)) %>%
  ggplot(aes(x = tmin, y = tmax)) +
    geom_hex() + 
    viridis::scale_fill_viridis(name = "", 
                                option = "plasma") + 
    theme(legend.position = "bottom",  
          legend.key.height = unit(0.1, "in"), 
          legend.key.width = unit(0.5, "in")) + 
    labs(x = "Minimum Temperature", 
         y = "Maximum Temperature") + 
    scale_y_continuous(position = "right")
  
snow_1981_2010 <- noaa_data %>%
  filter(snow > 0 & snow < 100) %>%
  mutate(year = as.factor(year)) %>%
  ggplot(aes(x = snow, fill = year, color = year)) +
  geom_density(alpha = 0.01) +
    viridis::scale_fill_viridis(name = "Year", 
                                discrete = TRUE) + 
    viridis::scale_color_viridis(name = "Year",
                                 discrete = TRUE, 
                                 option = "inferno") + 
    labs(x = "Snowfall", 
         y = "Density") + 
    theme(legend.position = "bottom", 
          legend.direction = "horizontal", 
          legend.key.size = unit(0.1, "in"), 
          legend.text = element_text(size = 6)) + 
    guides(fill = guide_legend(ncol = 6))

snow_1981_2010 + temp_hex
```




