---
title: "P8105: Homework 3"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

theme_set(theme_bw(base_size = 9))
```

## Problem 1

#### Importing and cleaning BRFSS data 

```{r importing brfss data}
brfss_data <- p8105.datasets::brfss_smart2010 %>% 
  janitor::clean_names()

brfss_data <- brfss_data %>% 
  rename(state = locationabbr, 
         location = locationdesc) %>% 
  filter(topic == "Overall Health") %>% 
  select(-(class:question), 
                       -sample_size, 
                       -(confidence_limit_low:geo_location)) %>% 
  mutate(response = as.factor(response))

brfss_data$response <- fct_relevel(brfss_data$response, 
                                   "Excellent", 
                                   "Very good", 
                                   "Good")
```

#### Questions and plots

```{r calculating 7 obs in 2002}
brfss_data %>% 
  filter(year == 2002) %>% 
  distinct(state, location) %>% 
  count(state) %>% 
  filter(n == 7) %>% 
  rename("State" = state, 
         "# Locations" = n) %>% 
  knitr::kable()
```

In 2002, the states Connecticut, Florida, and North Carolina were observed at 7 locations. 

```{r creating spaghetti plot, out.width = "90%", fig.align = "center", dpi = 300}
brfss_data %>% 
  group_by(state, year) %>% 
  distinct(location) %>% 
  count(state) %>% 
  ggplot(aes(x = year, y = n)) + 
    geom_line(aes(color = state)) + 
    viridis::scale_color_viridis(
      name = "", 
      discrete = TRUE, 
      option = "magma") +
    labs(title = "Figure 1: Spaghetti plot of number of locations across states from 2002 to 2010", 
         x = "Year", 
         y = "Number of Locations") + 
    theme(legend.position = "bottom", 
          legend.direction = "horizontal", 
          legend.key.width = unit(.1, "in")) + 
    guides(color = guide_legend(ncol = 17))
```

Figure 1 shows the trends in the number of locations across all 50 states and the District of Columbia. From 2002 to 2010, all states except Florida had less than 20 locations. Furthermore, it appears that most states had a relatively constant number of locations over the eight year period. 

```{r table proportion excellent responses NY 2002/06/10, fig.align = "center"}
brfss_data %>% 
  filter(year %in% c(2002, 2006, 2010), 
         state == "NY") %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(prop_excel =  (excellent) / (excellent + fair + good + poor + very_good)) %>% 
  group_by(year) %>% 
  summarize("Average proportion excellent" = round(mean(prop_excel), 4), 
            "Standard deviation" = round(sd(prop_excel), 4)) %>% 
  rename(Year = year) %>% 
  knitr::kable()
```

Table 2 contains the average proportion of excellent responses across locations in New York for 2002, 2006, and 2010. A small decrease is observed from 2002 to 2006 and then remains constant from 2006 to 2010. The standard error decreases in 2010, most likely indicating that more responses were collected that year. 

```{r average proportion response category across location by state, warning = FALSE, fig.height = 7, fig.align = "center", dpi = 300, out.width = "100%"}
library(patchwork)

avg_response_year_state <- 
  brfss_data %>%
  mutate(year = as.factor(year)) %>% 
  group_by(year, state, response) %>%
  summarize(avg_response = mean(data_value))

poor_dist <- avg_response_year_state %>%
  filter(response == "Poor") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) + 
    geom_text(x = 0, y = 0.40, 
              label = "Poor", 
              size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    viridis::scale_fill_viridis(discrete = TRUE, 
                                option = "magma",
                                guide = FALSE) + 
    theme(axis.text.x = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) + 
    labs(title = "Figure 2: Density plots of the proportion of different respones across states from 2002 to 2010", 
         y = "", 
         x = "")

fair_dist <- avg_response_year_state %>%
  filter(response == "Fair") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) +
    geom_text(x = 0, y = 0.15, 
              label = "Fair", size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    viridis::scale_fill_viridis(discrete = TRUE, 
                                option = "magma",
                                guide = FALSE) + 
    theme(axis.text.x = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) + 
    labs(y = "", x = "")

good_dist <- avg_response_year_state %>%
  filter(response == "Good") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) +
    geom_text(x = 0, y = 0.15, 
              label = "Good", size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    viridis::scale_fill_viridis(discrete = TRUE, 
                                option = "magma", 
                                guide = FALSE) + 
    theme(axis.text.x = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) +
    labs(y = "", x = "") 

v_good_dist <- avg_response_year_state %>%
  filter(response == "Very good") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) +
    geom_text(x = 1, y = 0.125, 
              label = "Very good", size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    viridis::scale_fill_viridis(discrete = TRUE, 
                                option = "magma",
                                guide = FALSE) + 
    theme(axis.text.x = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) + 
    labs(y = "", x = "")

excel_dist <- avg_response_year_state %>%
  filter(response == "Excellent") %>%
  ggplot(aes(x = avg_response, fill = year)) +
    geom_density(alpha = 0.5, color = NA) +
    geom_text(x = 1, y = 0.15, 
              label = "Excellent", size = 3) + 
    scale_x_continuous(limits = c(0, 45), 
                       breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45)) + 
    labs(y = "", x = "Response proportion") +
    viridis::scale_fill_viridis(name = "Year",
                                discrete = TRUE, 
                                option = "magma") +  
    theme(legend.position = "bottom",
          legend.direction = "horizontal", 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) + 
    guides(fill = guide_legend(ncol = 10)) 
    

poor_dist / fair_dist / good_dist / v_good_dist / excel_dist
```

Figure 2 shows density plots of the different response categories from 2002 to 2010. Because all of the plots are on the same scale, you can observe the average increase in the proportion of responses from poor up to very good. After very good, the proportion of responses then slightly decreases for the excellent category. It also appears that the distributions within each category remains relatively constant, likely indicating that response does not vary over time. 

## Problem 2

```{r importing insta cart data}
insta_data <- p8105.datasets::instacart %>% 
  janitor::clean_names() %>% 
  mutate(order_dow = order_dow + 1)

days <- c("Sunday",
          "Monday",
          "Tuesday",
          "Wednesday",
          "Thursday",
          "Friday",
          "Saturday")

insta_data$order_dow <- days[insta_data$order_dow]


insta_data$order_dow <- fct_relevel(insta_data$order_dow,
                                    "Sunday",
                                    "Monday",
                                    "Tuesday",
                                    "Wednesday",
                                    "Thursday",
                                    "Friday",
                                    "Saturday")
```

The Instacart dataset contains information on online grocery store orders during the year 2017 from the online company Instacart. The dataset has `r nrow(insta_data)` observations and `r ncol(insta_data)` variables. Each observation is a product from an order. Important variables include product IDs/names, the number of times the user has reordered a product, day and time information for variables, and how long it has been since a users last order. There are `r insta_data %>% group_by(order_id) %>% distinct(order_id) %>% nrow()` distinct customer orders. 

```{r aisles information}
numb_orders <- insta_data %>%
  group_by(aisle) %>%
  summarize(n = n()) %>%
  arrange(desc(n))
```

```{r items ordered in each aisle, fig.height = 15, fig.align = "center", dpi = 300}
numb_orders %>% 
  mutate(aisle = forcats::fct_reorder(aisle, n, .desc = TRUE)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  coord_flip() + 
  geom_bar(stat = "identity", fill = "#a888bd") +
    labs(title = "Figure 3: Number of orders across all aisles", 
         y = "Number of Orders", 
         x = "Aisle") + 
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank()) 
```

There are `r insta_data %>% distinct(aisle_id) %>% count()` aisles in the dataset. Figure 3 shows the number of orders across all aisles, ordered from least to most. Fresh vegetables and fresh fruits are ordered most with `r max(numb_orders$n)` and `r numb_orders %>% filter(aisle == "fresh fruits") %>% select(n)` orders respectively. Followed by packaged vegetables and fruits. The least ordered items are those coming from the beauty aisle, `r min(numb_orders$n)` orders. While the plot is rather large, it is purposefully ordered such that aisles that are most ordered from are directly next to the x axis scale. In addition, by making a horizontal bar chart instead of vertical chart, the aisle names are more easily read than they would have been if they were angled on the x-axis. 

```{r most popular items in 3 aisles}
insta_data %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(n = n()) %>% 
  filter(n == max(n)) %>% 
  arrange(desc(n)) %>%
  rename(Aisle = aisle, 
         "Product Name" = product_name, 
         "# Obs" = n) %>% 
  knitr::kable()
```

```{r mean hour of the day}
insta_data %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(avg_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = avg_hour) %>% 
  rename("Product Name" = product_name) %>% 
  knitr::kable(align = "c")
```

## Problem 3

```{r importing and cleaning NY NOAA data}
noaa_data <- p8105.datasets::ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(date, c("year", "month", "day"), sep = "-") %>% 
  mutate(tmax = as.double(tmax) / 10, 
         tmin = as.double(tmin) / 10, 
         prcp = prcp / 10,
         month = month.name[as.integer(month)], 
         year = as.integer(year))
```

The NOAA dataset contains weather information for all five New York state weather stations from 1981 to 2010. The dataset has `r nrow(noaa_data)` observations and `r ncol(noaa_data)` variables. Each observation represents one day from 1981 to 2010 for one of the weather stations the corresponding data was collected at. The variables provide information on that days minimum temperature and maximum temperature in degrees celsius, the snowfall for that day in millimeters, the snowdepth for that day in millimeters, and the amount of precipitation for that day in millimeters. It is important to note that uncleaned dataset reported minimum daily temperature and maximum daily temperature in tenths of degrees celsius and precipitation in tenths of millimeters. However, these were converted to proper units for ease of interpretation. The present NOAA dataset contains large amounts of missing data. Of all observations, `r noaa_data %>% filter_all(any_vars(is.na(.))) %>% count()` contain at least one missing value. In addition, `r noaa_data %>% filter_at(vars(prcp:tmin), all_vars(is.na(.))) %>% count()` have missing values for all five key variables. 

```{r average snow}
noaa_data %>% 
  group_by(month) %>% 
  summarize(avg_snow = round(mean(snow, na.rm = TRUE), 4))
```

```{r average daily temp plot in january and july, dpi = 300, fig.align = "center", fig.retina = 1, fig.asp = .6, out.width = "100%"}
avg_daily_temp <- noaa_data %>%
  filter(month %in% c("January", "July")) %>%
  mutate(avg_temp = (tmin + tmax) / 2)

avg_daily_temp %>% 
  filter(month %in% c("January", "July")) %>% 
  group_by(year, month) %>% 
  summarize(avg_temp = mean(avg_temp, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = avg_temp)) + 
    geom_line(color = "#7496D2", size = 1) + 
  facet_grid(~ month, 
             scales = "free") + 
  labs(x = "Year", 
       y = "Average Daily Temperature (°C)") +
  theme(axis.text.x = element_text(angle = 45,
                                   vjust = 0.4), 
        strip.background = element_rect(fill = "black"), 
        strip.text = element_text(color = "white", 
                                  face = "bold"))
```

```{r snow and temperature plot, dpi = 300, out.width = "100%", fig.asp = .5, fig.align = "center", fig.height = 6}
temp_hex <- noaa_data %>%
  filter(!is.na(tmin),
         !is.na(tmax)) %>%
  ggplot(aes(x = tmin, y = tmax)) +
    geom_hex() + 
    viridis::scale_fill_viridis(name = "", 
                                option = "plasma") + 
    theme(legend.position = "bottom",  
          legend.key.height = unit(0.1, "in"), 
          legend.key.width = unit(0.5, "in")) + 
    labs(x = "Minimum Temperature", 
         y = "Maximum Temperature") + 
    scale_y_continuous(position = "right")
  
snow_1981_2010 <- noaa_data %>%
  filter(snow > 0 & snow < 100) %>%
  mutate(year = as.factor(year)) %>%
  ggplot(aes(x = snow, fill = year, color = year)) +
  geom_density(alpha = 0.01) +
    viridis::scale_fill_viridis(name = "Year", 
                                discrete = TRUE) + 
    viridis::scale_color_viridis(name = "Year",
                                 discrete = TRUE, 
                                 option = "cividis", 
                                 direction = -1) + 
    labs(x = "Snowfall", 
         y = "Density") + 
    theme(legend.position = "bottom", 
          legend.direction = "horizontal", 
          legend.key.size = unit(0.1, "in"), 
          legend.text = element_text(size = 6)) + 
    guides(fill = guide_legend(ncol = 6))

snow_1981_2010 + temp_hex
```




